- 数据校验(page 12)
  > 于是犹太人发明了一种类似于我们今天计算机和通信中的校验码的方法。他们把每一个希伯来字母对于一个数字，这样每行文字加起来便得到一个特殊的数字，这个数字便成为了这一行的校验码。同样，对于每一列也是这样处理。当犹太学者抄完一页《圣经》时，他们需要把每一行的文字加起来，看看新的校验码是否和原文的相同。

- 图灵测试(page 16)
  > 让人与机器进行交流，如果人无法判断自己交流的对象是人还是机器，就说明这个机器有智能了。
  
- 翻译统计语言模型
  1. 条件概率(page 28)
     > 假定S表示某一个有意义的句子，由一连串特定顺序排列的词W1,W2,W3,...,Wn组成，这里n是句子的长度。
     ```
     P(S)=P(W1,W2,...,Wn)=P(W1)*P(W2|W1)*(W3|W1,W2)...P(Wn|W1,W2,...,Wn-1)
     ```
  2. 统计语言的二元模型-马尔科夫假设(page 29)
     > 假设任意一个词Wi出现的概率只同它前面的词Wi-1有关。
     ```
     P(S)=P(W1)*P(W2|W1)*(W3|W2)...P(Wi|Wi-1)...P(Wn|Wn-1)
     ```
  3. 估计条件概率P(Wi|Wi-1)(page 30)
     ```
     P(Wi|Wi-1)=P(Wi-1,Wi)/P(Wi-1)
     有了大量的语料库，只要数一数Wi-1,Wi这对词在统计的文本中前后相邻出现了多少次#(Wi-1,Wi),以及Wi-1本身在同样的文本中出现了多少次#(Wi-1)
     P(Wi|Wi-1)=#(Wi-1,Wi)/#(Wi-1)
     ```
   4. 古德-图灵估计(page 35)
     > 对于没有看见的事件，我们不能认为它发生的概率就是零，因此我们从概率的总量中，分配一个很小的比例给这些没有看见的事件。这样一来，看见的那些事件的概率总和就要小于1，因此，需要将所有看见的事件的概率调小一点，至于要小多少，要根据"越是不可信的统计折扣越多"的方法进行。

- 分词
   1. 查字典分词(page 42)
   > 把一个句子从左到右扫描一遍，遇到字典里有的词就标识出来，遇到复合词(比如"上海大学")就找到最长的词匹配，遇到不认识的字串就分割成单字词，于是简单的分词就完成了。
   